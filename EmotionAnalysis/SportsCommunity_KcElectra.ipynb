{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4e8a0ec27c0446e8af527d84f77b8e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_715626e93c8b4a0ebd6969dae4cf2911",
              "IPY_MODEL_7d59d54eb2834915826ef5c14d481cfe",
              "IPY_MODEL_b7a430cae8c9469b8e4b7cccd388e869"
            ],
            "layout": "IPY_MODEL_6eb871023cc643cf9a90894a41c93a49"
          }
        },
        "715626e93c8b4a0ebd6969dae4cf2911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d21697fbf440442598313d6021d2a638",
            "placeholder": "​",
            "style": "IPY_MODEL_d8ba11c322454ff2aac7c6da39e7e577",
            "value": "Map: 100%"
          }
        },
        "7d59d54eb2834915826ef5c14d481cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf89bcdc606645c0b0b7b62e7072869a",
            "max": 250000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a95ed6cdcc0e47b79eb219111ecc1908",
            "value": 250000
          }
        },
        "b7a430cae8c9469b8e4b7cccd388e869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac5c4b3a3c4e4d95bf47bc0b0931bef1",
            "placeholder": "​",
            "style": "IPY_MODEL_dff96752fda942cc9d113bb5febf902e",
            "value": " 250000/250000 [00:19&lt;00:00, 13805.37 examples/s]"
          }
        },
        "6eb871023cc643cf9a90894a41c93a49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d21697fbf440442598313d6021d2a638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8ba11c322454ff2aac7c6da39e7e577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf89bcdc606645c0b0b7b62e7072869a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a95ed6cdcc0e47b79eb219111ecc1908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac5c4b3a3c4e4d95bf47bc0b0931bef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dff96752fda942cc9d113bb5febf902e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40831cb9161a4a0f93a6779b00a38354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4d6987e081e4d70b0e832f0b8334baa",
              "IPY_MODEL_87857b4cd5ed4ba9abd52e4d784ee8b3",
              "IPY_MODEL_6d3091f443404fbab89ffae814629515"
            ],
            "layout": "IPY_MODEL_03f11b3e36734a5f87fdf8f2f93cdbbc"
          }
        },
        "d4d6987e081e4d70b0e832f0b8334baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21492f72e26465e88578d06d58544ad",
            "placeholder": "​",
            "style": "IPY_MODEL_502aaaa6c5314d1282aebb80f422f031",
            "value": "Map: 100%"
          }
        },
        "87857b4cd5ed4ba9abd52e4d784ee8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4af4a23f0ad64a3a84faa090b336e9dc",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f75546afcd840b7b1bec118a3337b25",
            "value": 50000
          }
        },
        "6d3091f443404fbab89ffae814629515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a12a11f7ba44fa0bb474b718cf891c8",
            "placeholder": "​",
            "style": "IPY_MODEL_35db6ceb324c49dab4ebc98e4cea4580",
            "value": " 50000/50000 [00:03&lt;00:00, 17473.60 examples/s]"
          }
        },
        "03f11b3e36734a5f87fdf8f2f93cdbbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e21492f72e26465e88578d06d58544ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "502aaaa6c5314d1282aebb80f422f031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4af4a23f0ad64a3a84faa090b336e9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f75546afcd840b7b1bec118a3337b25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a12a11f7ba44fa0bb474b718cf891c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35db6ceb324c49dab4ebc98e4cea4580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. 준비 (GPU T4로 세팅)**"
      ],
      "metadata": {
        "id": "tf24HDfQaMhM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAK5WdhJ7z5Y",
        "outputId": "0c16bb19-019b-4293-e5f0-3448e55c256c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-79d9a0fa-a00b-385d-945f-f2fe2437720e)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L || echo \"No GPU detected (ok for quick tests)\"\n",
        "!pip -q install \"transformers==4.44.0\" \"datasets==3.0.1\" \"torch\" \"sentencepiece\" \\\n",
        "                 \"pandas\" \"numpy\" \"matplotlib\" \"tqdm\" \"evaluate\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Github Link 추가하여 데이터 불러오기, 데이터 파일 명만 추가하여 파일 구분**"
      ],
      "metadata": {
        "id": "Q-Bc6qGoaWP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# GitHub raw URL 목록\n",
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round1_Bahrain.csv\",\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round3_Australia.csv\",\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round4_Japan.csv\",\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round7_Italy.csv\",\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round10_Spain.csv\",\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round12_UnitedKingdom.csv\",\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round13_Hungary.csv\",\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round15_Netherlands.csv\",\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round17_Singapore.csv\",\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round22_USA.csv\",\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round23_Qatar.csv\",\n",
        "    \"https://raw.githubusercontent.com/hyunseo-adastra/SocialData_SportsCommunity/main/F1_forKCElectra/Round24_AbuDhabi.csv\"\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for url in urls:\n",
        "    # 파일 이름만 추출 (예: Round1_Bahrain.csv → Round1_Bahrain)\n",
        "    filename = url.split(\"/\")[-1].replace(\".csv\", \"\")\n",
        "\n",
        "    # CSV 읽기\n",
        "    df = pd.read_csv(url)\n",
        "\n",
        "    # 파일 이름 컬럼 추가\n",
        "    df[\"source_file\"] = filename\n",
        "\n",
        "    dfs.append(df)\n",
        "\n",
        "# 모든 데이터 합치기\n",
        "df_all = pd.concat(dfs, ignore_index=True)"
      ],
      "metadata": {
        "id": "48IlCUZ--TW9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. 데이터 컬럼 선택 및 클리닝**\n",
        "\n",
        "클리닝\n",
        "- 디시인사이드의 경우 \"dc official App\" 삭제\n",
        "- 해시태그, 멘션, URL, 공백 삭제\n",
        "- \"ㅋㅋㅋ\"나 \"!!!\" 등의 표현 수는 남겨두기\n",
        "\n",
        "**추후논의하여 클리닝 수정 가능"
      ],
      "metadata": {
        "id": "twsKaWzAaiOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# 컬럼 찾아내기\n",
        "TEXT_CAND = [\n",
        "    \"text\",\"content\",\"message\",\"body\",\"comment\",\"chat\",\n",
        "    \"post_content\",\"post_text\",\"desc\",\"description\"\n",
        "]\n",
        "TITLE_CAND = [\"title\",\"post_title\",\"subject\",\"headline\"]\n",
        "TIME_CAND = [\n",
        "    \"timestamp\",\"time\",\"created_at\",\"createdAt\",\"date\",\"datetime\",\n",
        "    \"post_timestamp\",\"post_time\",\"post_date\",\"published_at\",\"created\"\n",
        "]\n",
        "GROUP_CAND = [\"team\",\"team_name\",\"driver\",\"player\",\"user\",\"author\",\"username\"]\n",
        "\n",
        "def pick_col(cols, cand_list):\n",
        "    cols_set = set(cols)\n",
        "    # 1) 정확히 일치\n",
        "    for c in cand_list:\n",
        "        if c in cols_set:\n",
        "            return c\n",
        "    # 2) 부분 포함(대소문자 무시)\n",
        "    for col in cols:\n",
        "        for k in cand_list:\n",
        "            if k.lower() in col.lower():\n",
        "                return col\n",
        "    return None\n",
        "\n",
        "# 텍스트 결합(제목+본문)도 지원하기 위해 보조 함수\n",
        "def pick_text_columns(cols):\n",
        "    text_col = pick_col(cols, TEXT_CAND)\n",
        "    title_col = pick_col(cols, TITLE_CAND)\n",
        "    return text_col, title_col\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 데이터 클리닝\n",
        "# \"dc official app\" 변형 전부 제거 (따옴표/하이픈/대소문자/앞뒤공백 포함)\n",
        "_DC_OFFICIAL_PAT = re.compile(\n",
        "    r\"\"\"\n",
        "    ^\\s*        # 라인 시작 공백\n",
        "    [\\-\\–\\—\\u2013\\u2014]*\\s*   # 하이픈 류와 공백(선택)\n",
        "    [\"']?\\s*    # 따옴표(선택)\n",
        "    d\\s*c\\s*o\\s*f\\s*f\\s*i\\s*c\\s*i\\s*a\\s*l\\s*a\\s*p\\s*p # dc official app(문자 사이 공백 허용 대비)\n",
        "    \\s*[\"']?    # 따옴표(선택)\n",
        "    \\s*$        # 라인 끝\n",
        "    \"\"\",\n",
        "    re.IGNORECASE | re.VERBOSE\n",
        ")\n",
        "\n",
        "def remove_dc_official_app_lines(s: str) -> str:\n",
        "    \"\"\"문장 중 개별 라인으로 들어온 '- dc official App' 류 라인을 날림.\"\"\"\n",
        "    # 줄 단위로 쪼개서 해당 패턴에 맞는 줄 제거\n",
        "    lines = re.split(r\"[\\r\\n]+\", s)\n",
        "    kept = [ln for ln in lines if not _DC_OFFICIAL_PAT.match(ln)]\n",
        "    return \"\\n\".join(kept).strip()\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        return \"\"\n",
        "    # 0) 먼저 dc official app 같은 라인 제거\n",
        "    s = remove_dc_official_app_lines(s)\n",
        "\n",
        "    # 1) URL 제거\n",
        "    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)\n",
        "\n",
        "    # 2) 멘션/해시태그 제거\n",
        "    s = re.sub(r\"[@#]\\w+\", \" \", s)\n",
        "\n",
        "    # 생략 3) 반복 문자 축약 (ㅋㅋㅋㅋ -> ㅋㅋ, 아아아아 -> 아아, !!!!! -> !!)\n",
        "    # s = re.sub(r\"([ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9!?.])\\1{2,}\", r\"\\1\\1\", s)\n",
        "\n",
        "    # 생략 4) 이모지/특수문자 과도한 것 정리 (한글/영문/숫자/기본문장부호만 유지)\n",
        "    # s = re.sub(r\"[^\\w\\s가-힣ㄱ-ㅎㅏ-ㅣ!?.]\", \" \", s, flags=re.UNICODE)\n",
        "\n",
        "    # 생략 5) 팀명/드라이버 약칭 정규화 (원하면 계속 추가)\n",
        "    # team_map = {\n",
        "    #    \"T1\": \"티원\",\n",
        "    #    \"GEN\": \"젠지\",\n",
        "    #    \"VER\": \"페르스타펜\",\n",
        "    #    \"HAM\": \"해밀턴\",\n",
        "    #}\n",
        "    #for short_name, full_name in team_map.items():\n",
        "    #    s = re.sub(fr\"\\b{short_name}\\b\", full_name, s, flags=re.IGNORECASE)\n",
        "\n",
        "    # 6) 공백 정리\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "####클리닝은 논의 후 추가\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "df = df_all.copy()\n",
        "\n",
        "# 텍스트/제목/시간/그룹 컬럼 자동 선택\n",
        "TEXT_COL, TITLE_COL = pick_text_columns(df.columns)\n",
        "TIME_COL = pick_col(df.columns, TIME_CAND)\n",
        "GROUP_COL = pick_col(df.columns, GROUP_CAND)\n",
        "\n",
        "print(f\"Detected -> TEXT_COL={TEXT_COL}, TITLE_COL={TITLE_COL}, TIME_COL={TIME_COL}, GROUP_COL={GROUP_COL}\")\n",
        "\n",
        "# 텍스트 컬럼이 없으면 제목만이라도 사용, 그것도 없으면 에러\n",
        "if TEXT_COL is None and TITLE_COL is None:\n",
        "    raise ValueError(\"텍스트(채팅/본문/내용) 컬럼을 못 찾았어요. 필요 시 df_raw.rename(columns={'실제컬럼명':'text'}) 후 재실행하세요.\")\n",
        "\n",
        "# 텍스트 결합: 본문+제목 (제목이 있으면 앞에 붙이기)\n",
        "if TEXT_COL is not None and TITLE_COL is not None:\n",
        "    df[\"_raw_text_for_clean\"] = (\n",
        "        df[TITLE_COL].astype(str).fillna(\"\") + \" \" + df[TEXT_COL].astype(str).fillna(\"\")\n",
        "    )\n",
        "elif TEXT_COL is not None:\n",
        "    df[\"_raw_text_for_clean\"] = df[TEXT_COL].astype(str).fillna(\"\")\n",
        "else:\n",
        "    df[\"_raw_text_for_clean\"] = df[TITLE_COL].astype(str).fillna(\"\")\n",
        "\n",
        "# 클리닝\n",
        "df[\"clean_text\"] = df[\"_raw_text_for_clean\"].map(normalize_text)\n",
        "\n",
        "# 타임스탬프 파싱(있으면). 문자열/숫자 혼재 대응 & 실패는 NaT로\n",
        "if TIME_COL is not None:\n",
        "    # 숫자형 유닉스 타임스탬프(초/밀리초)일 가능성도 처리\n",
        "    if np.issubdtype(df[TIME_COL].dtype, np.number):\n",
        "        # 초/밀리초 구분 추정\n",
        "        median_val = df[TIME_COL].dropna().astype(float).median() if df[TIME_COL].notna().any() else None\n",
        "        if median_val and median_val > 1e12:\n",
        "            # 밀리초로 보임\n",
        "            df[\"ts\"] = pd.to_datetime(df[TIME_COL], unit=\"ms\", errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
        "        elif median_val and median_val > 1e9:\n",
        "            # 초로 보임\n",
        "            df[\"ts\"] = pd.to_datetime(df[TIME_COL], unit=\"s\", errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
        "        else:\n",
        "            # 일반 숫자 -> 문자열 변환 후 파서에 맡김\n",
        "            df[\"ts\"] = pd.to_datetime(df[TIME_COL].astype(str), errors=\"coerce\")\n",
        "    else:\n",
        "        df[\"ts\"] = pd.to_datetime(df[TIME_COL], errors=\"coerce\")\n",
        "else:\n",
        "    df[\"ts\"] = pd.NaT\n",
        "\n",
        "# 빈 텍스트/공백만 남은 행 제거\n",
        "df[\"clean_text\"] = df[\"clean_text\"].fillna(\"\").str.strip()\n",
        "df = df[df[\"clean_text\"].astype(bool)].reset_index(drop=True)\n",
        "\n",
        "# 편의: source_file에서 라운드명 추출\n",
        "if \"source_file\" in df.columns:\n",
        "    # 예: Round22_USA -> round_num=22, gp_name=USA\n",
        "    m = df[\"source_file\"].str.extract(r\"Round\\s*([0-9]+)[\\s_]+(.+)\", expand=True)\n",
        "    df[\"round_num\"] = pd.to_numeric(m[0], errors=\"coerce\")\n",
        "    df[\"gp_name\"] = m[1].fillna(\"\").str.replace(\"_\", \" \").str.strip()\n",
        "\n",
        "print(\"After cleaning, rows:\", len(df))\n",
        "display_cols = [\"clean_text\",\"ts\"]\n",
        "if \"source_file\" in df.columns: display_cols.append(\"source_file\")\n",
        "if \"round_num\" in df.columns:   display_cols.append(\"round_num\")\n",
        "if \"gp_name\" in df.columns:     display_cols.append(\"gp_name\")\n",
        "if GROUP_COL is not None:       display_cols.append(GROUP_COL)\n",
        "print(df[display_cols].head(10))"
      ],
      "metadata": {
        "id": "sI0hI7FmMAk8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5082eaf-4f3c-45fa-bd48-4b967d0b5d3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected -> TEXT_COL=post_content, TITLE_COL=post_title, TIME_COL=post_timestamp, GROUP_COL=None\n",
            "After cleaning, rows: 43134\n",
            "                              clean_text                  ts     source_file  \\\n",
            "0                     와 존나설레 ㅅㅂ 가보자고ㅜㅜㅜㅡ 2024-03-03 00:04:04  Round1_Bahrain   \n",
            "1                      스포한다 물탕이가 르끌레 꽂는다 2024-03-03 00:04:06  Round1_Bahrain   \n",
            "2        라마단 <<< 고마우면 개추 ㅋㅋㅋ 덕분에 편하게본다 ㅆ 2024-03-03 00:04:09  Round1_Bahrain   \n",
            "3              와 씹 진짜 저 초록색 흉물 좆같네 ㅅㅂㅋㅋㅋ 2024-03-03 00:04:10  Round1_Bahrain   \n",
            "4                   개ㅈ핀 도착 ㅋㅋㅋㅋㅋㅋㅋㅋㅋ nan 2024-03-03 00:04:07  Round1_Bahrain   \n",
            "5                  ㅋㅋㅋ 알핀이 마지막ㅋㅋㅋㅋ ㅋㅋㅋㅋㅋ 2024-03-03 00:04:11  Round1_Bahrain   \n",
            "6  It's lights out and away we go!!! nan 2024-03-03 00:04:14  Round1_Bahrain   \n",
            "7                          드가좤ㅋㅋㅋㅋㅋㅋ nan 2024-03-03 00:04:15  Round1_Bahrain   \n",
            "8                          츠노다 가자 ㅋㅋ nan 2024-03-03 00:04:18  Round1_Bahrain   \n",
            "9                          스타트!!!!!! nan 2024-03-03 00:04:17  Round1_Bahrain   \n",
            "\n",
            "   round_num  gp_name  \n",
            "0          1  Bahrain  \n",
            "1          1  Bahrain  \n",
            "2          1  Bahrain  \n",
            "3          1  Bahrain  \n",
            "4          1  Bahrain  \n",
            "5          1  Bahrain  \n",
            "6          1  Bahrain  \n",
            "7          1  Bahrain  \n",
            "8          1  Bahrain  \n",
            "9          1  Bahrain  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. 파인튜닝을 위한 데이터셋 불러오기**\n",
        "\n",
        "사용데이터: NSMC, Steam\n",
        "- NSMC 네이버 영화 댓글: https://github.com/e9t/nsmc\n",
        "- Steam 리뷰: https://github.com/bab2min/corpus"
      ],
      "metadata": {
        "id": "-GrKglBBayqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict, concatenate_datasets\n",
        "import pandas as pd\n",
        "\n",
        "# NSMC (네이버 영화리뷰) 불러오기\n",
        "nsmc = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files={\n",
        "        \"train\": \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\",\n",
        "        \"test\":  \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\",\n",
        "    },\n",
        "    delimiter=\"\\t\"\n",
        ")\n",
        "print(\"NSMC loaded:\", nsmc)\n",
        "\n",
        "# Steam 한국어 리뷰 데이터 불러오기\n",
        "# 파일 구조: 각 줄이 \"label\\ttext\" 형태\n",
        "steam = load_dataset(\n",
        "    \"csv\",\n",
        "    data_files={\"train\": \"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/steam.txt\"},\n",
        "    delimiter=\"\\t\",\n",
        "    column_names=[\"label\", \"text\"]\n",
        ")\n",
        "print(\"Steam dataset loaded:\", steam)\n",
        "\n",
        "# 컬럼 구조 통일\n",
        "# NSMC는 \"document\" 컬럼 → text로 이름 변경\n",
        "nsmc = nsmc.rename_column(\"document\", \"text\")\n",
        "\n",
        "# 라벨 타입 통일 (float → int 등)\n",
        "nsmc[\"train\"] = nsmc[\"train\"].map(lambda x: {\"label\": int(x[\"label\"])})\n",
        "nsmc[\"test\"]  = nsmc[\"test\"].map(lambda x: {\"label\": int(x[\"label\"])})\n",
        "steam[\"train\"] = steam[\"train\"].map(lambda x: {\"label\": int(x[\"label\"])})\n",
        "\n",
        "# Steam train 데이터와 NSMC train/test 합치기\n",
        "train_merged = concatenate_datasets([nsmc[\"train\"], steam[\"train\"]])\n",
        "test_merged  = nsmc[\"test\"]  # Steam에는 test 세트가 없으므로 그대로 사용\n",
        "\n",
        "merged = DatasetDict({\"train\": train_merged, \"test\": test_merged})\n",
        "print(\"통합 DatasetDict 구성 완료:\")\n",
        "print(merged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cABdtdSaLXA",
        "outputId": "3b86d3ac-4ee9-4734-8303-296e5c465831"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NSMC loaded: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'document', 'label'],\n",
            "        num_rows: 150000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'document', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n",
            "Steam dataset loaded: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['label', 'text'],\n",
            "        num_rows: 100000\n",
            "    })\n",
            "})\n",
            "통합 DatasetDict 구성 완료:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'text', 'label'],\n",
            "        num_rows: 250000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'text', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. KcElectra 모델 불러오기, Tokenizing**"
      ],
      "metadata": {
        "id": "hARszdg3ds3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import DataCollatorWithPadding\n",
        "import evaluate\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 모델 후보. 첫 번째가 잘 불리면 그대로 사용.\n",
        "BASES = [\"beomi/KcELECTRA-base\", \"beomi/KcELECTRA-base-v2022\"]\n",
        "\n",
        "tok = None\n",
        "MODEL_BASE = None\n",
        "for base in BASES:\n",
        "    try:\n",
        "        tok = AutoTokenizer.from_pretrained(base)\n",
        "        MODEL_BASE = base\n",
        "        print(\"Using base:\", base)\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(\"Tokenizer load failed:\", base, \"->\", e)\n",
        "\n",
        "if tok is None:\n",
        "    raise RuntimeError(\"KcELECTRA 토크나이저 로드 실패\")\n",
        "\n",
        "def tok_fn(batch):\n",
        "    # Use the \"text\" column for tokenization as it's available in the merged dataset\n",
        "    texts = [str(text) for text in batch[\"text\"]]\n",
        "    out = tok(texts, truncation=True, max_length=128)\n",
        "    # Add the label column\n",
        "    out[\"labels\"] = batch[\"label\"]\n",
        "    return out\n",
        "\n",
        "\n",
        "# nsmc 데이터셋 대신 클리닝된 df 데이터프레임을 사용\n",
        "# 데이터프레임을 Dataset 객체로 변환\n",
        "from datasets import Dataset\n",
        "# df_dataset = Dataset.from_pandas(df) # This is not used for training anymore\n",
        "\n",
        "# tokenized = df_dataset.map(\n",
        "#     tok_fn,\n",
        "#     batched=True,\n",
        "#     # remove_columns는 더 이상 nsmc 데이터셋을 사용하지 않으므로 필요 없습니다.\n",
        "#     # remove_columns=remove_cols\n",
        "# )\n",
        "\n",
        "\n",
        "collator = DataCollatorWithPadding(tokenizer=tok)\n",
        "metric_f1 = evaluate.load(\"f1\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_BASE,\n",
        "    num_labels=2 # 이진 분류 (긍정/부정)를 위한 num_labels=2\n",
        ")\n",
        "\n",
        "print(\"Tokenized dataset structure:\", merged) # Print the merged dataset structure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHZ_oOAqdufh",
        "outputId": "d2bf1012-3efe-4131-88a7-ba345b84a0d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using base: beomi/KcELECTRA-base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized dataset structure: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'text', 'label'],\n",
            "        num_rows: 250000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'text', 'label'],\n",
            "        num_rows: 50000\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. KcElectra Model Training(Finetuning)**"
      ],
      "metadata": {
        "id": "g2nklBFEdqai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# 훈련 인자 설정\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",          # 훈련 결과 및 체크포인트 저장 디렉토리\n",
        "    evaluation_strategy=\"epoch\",     # 에포크마다 평가 수행\n",
        "    save_strategy=\"epoch\",           # 에포크마다 모델 저장\n",
        "    learning_rate=2e-5,              # 학습률\n",
        "    per_device_train_batch_size=16,  # 장치당 훈련 배치 크기\n",
        "    per_device_eval_batch_size=16,   # 장치당 평가 배치 크기\n",
        "    num_train_epochs=1,              # 훈련 에포크 수 (빠른 테스트를 위해 1로 줄임)\n",
        "    weight_decay=0.01,               # 가중치 감소 (L2 정규화)\n",
        "    push_to_hub=False,               # Hugging Face Hub에 푸시하지 않음\n",
        "    report_to=\"none\",                # 로깅 비활성화\n",
        ")\n",
        "\n",
        "# 평가 메트릭 함수 정의\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric_f1.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Trainer 인스턴스 생성\n",
        "# 훈련 데이터셋은 수동으로 토큰화한 tokenized_inputs 리스트를 사용합니다.\n",
        "# 검증 데이터셋은 NSMC 테스트 데이터셋을 사용하여 토큰화해야 합니다.\n",
        "\n",
        "# NSMC 테스트 데이터셋 토큰화\n",
        "test_texts = [str(text) for text in nsmc[\"test\"][\"text\"]]\n",
        "test_labels = nsmc[\"test\"][\"label\"]\n",
        "\n",
        "# The previous tokenization logic was for `df_dataset` which is not the training data.\n",
        "# The training data should be `merged[\"train\"]` and the evaluation data `merged[\"test\"]`.\n",
        "# Also, the tokenization should be done using the `map` function of the Dataset object, not manually in a loop.\n",
        "\n",
        "# Tokenize the merged datasets\n",
        "tokenized_merged = merged.map(\n",
        "    tok_fn,\n",
        "    batched=True,\n",
        "    remove_columns=[\"id\", \"text\"] # Remove original text columns after tokenization\n",
        ")\n",
        "\n",
        "collator = DataCollatorWithPadding(tokenizer=tok)\n",
        "metric_f1 = evaluate.load(\"f1\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_BASE,\n",
        "    num_labels=2 # 이진 분류 (긍정/부정)를 위한 num_labels=2\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # 훈련할 모델\n",
        "    args=training_args,                  # 훈련 인자\n",
        "    train_dataset=tokenized_merged[\"train\"],         # 훈련 데이터셋\n",
        "    eval_dataset=tokenized_merged[\"test\"],           # 검증 데이터셋\n",
        "    data_collator=collator,              # 데이터 콜레이터\n",
        "    compute_metrics=compute_metrics,     # 평가 메트릭 함수\n",
        "    tokenizer=tok                        # 토크나이저\n",
        ")\n",
        "\n",
        "# 훈련 시작\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650,
          "referenced_widgets": [
            "4e8a0ec27c0446e8af527d84f77b8e2f",
            "715626e93c8b4a0ebd6969dae4cf2911",
            "7d59d54eb2834915826ef5c14d481cfe",
            "b7a430cae8c9469b8e4b7cccd388e869",
            "6eb871023cc643cf9a90894a41c93a49",
            "d21697fbf440442598313d6021d2a638",
            "d8ba11c322454ff2aac7c6da39e7e577",
            "cf89bcdc606645c0b0b7b62e7072869a",
            "a95ed6cdcc0e47b79eb219111ecc1908",
            "ac5c4b3a3c4e4d95bf47bc0b0931bef1",
            "dff96752fda942cc9d113bb5febf902e",
            "40831cb9161a4a0f93a6779b00a38354",
            "d4d6987e081e4d70b0e832f0b8334baa",
            "87857b4cd5ed4ba9abd52e4d784ee8b3",
            "6d3091f443404fbab89ffae814629515",
            "03f11b3e36734a5f87fdf8f2f93cdbbc",
            "e21492f72e26465e88578d06d58544ad",
            "502aaaa6c5314d1282aebb80f422f031",
            "4af4a23f0ad64a3a84faa090b336e9dc",
            "1f75546afcd840b7b1bec118a3337b25",
            "0a12a11f7ba44fa0bb474b718cf891c8",
            "35db6ceb324c49dab4ebc98e4cea4580"
          ]
        },
        "id": "NX0AwrekeXBl",
        "outputId": "1b64ce10-9ea2-4fca-8245-af39f9b71a7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/250000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e8a0ec27c0446e8af527d84f77b8e2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40831cb9161a4a0f93a6779b00a38354"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='255' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  255/15625 00:41 < 42:01, 6.10 it/s, Epoch 0.02/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# .to() doesn't accept non_blocking as kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: BatchEncoding.to() got an unexpected keyword argument 'non_blocking'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1754272902.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# 훈련 시작\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1947\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1948\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1949\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2246\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2247\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0;31m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                     \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0mnext_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# .to() doesn't accept non_blocking as kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;31m# `torch.Tensor.to(<int num>)` is not supported by `torch_npu` (see this [issue](https://github.com/Ascend/pytorch/issues/16)).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;31m# into a HalfTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_torch_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Attempting to cast a BatchEncoding to type {str(device)}. This is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. 감성분석**"
      ],
      "metadata": {
        "id": "ACiQ-6QDe0cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# MODEL_PATH를 훈련 결과가 저장된 디렉토리로 변경\n",
        "# './results' 디렉토리에 저장된 최신 체크포인트를 로드합니다.\n",
        "TRAINING_OUTPUT_DIR = \"./results\"\n",
        "BASE = \"beomi/KcELECTRA-base\"                # 토크나이저용 베이스\n",
        "\n",
        "# 가장 최근 체크포인트 디렉토리를 찾습니다.\n",
        "checkpoints = [d for d in glob.glob(f\"{TRAINING_OUTPUT_DIR}/checkpoint-*\") if os.path.isdir(d)]\n",
        "if not checkpoints:\n",
        "    raise FileNotFoundError(f\"No checkpoint directories found in {TRAINING_OUTPUT_DIR}\")\n",
        "\n",
        "# 체크포인트 이름에서 숫자를 추출하여 최신 체크포인트를 찾습니다.\n",
        "latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('-')[-1]))\n",
        "MODEL_PATH = latest_checkpoint\n",
        "print(f\"Loading model from: {MODEL_PATH}\")\n",
        "\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(BASE)\n",
        "# 훈련된 모델 로드\n",
        "clf = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH).eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def batched(lst, n=64):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i+n]\n",
        "\n",
        "probs = []\n",
        "for chunk in tqdm(batched(df[\"clean_text\"].tolist(), 64), total=(len(df)//64 + 1)):\n",
        "    enc = tok(chunk, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "    enc = {k:v.to(device) for k,v in enc.items()}\n",
        "    with torch.no_grad():\n",
        "        p = clf(**enc).logits.softmax(dim=-1).cpu().numpy()  # [:,0]=neg, [:,1]=pos\n",
        "    probs.append(p)\n",
        "\n",
        "probs = np.vstack(probs)\n",
        "df[\"p_neg\"], df[\"p_pos\"] = probs[:,0], probs[:,1]\n",
        "df[\"polarity_binary\"] = (df[\"p_pos\"] > df[\"p_neg\"]).astype(int)  # 1=pos, 0=neg\n",
        "\n",
        "# 휴리스틱 중립(신뢰도 낮은 샘플)\n",
        "conf = np.abs(df[\"p_pos\"] - 0.5) * 2  # 0..1\n",
        "NEUTRAL_THRESH = 0.20                 # 필요시 0.15~0.30에서 튜닝\n",
        "df[\"neutral_flag\"] = (conf < NEUTRAL_THRESH).astype(int)\n",
        "\n",
        "def to_ternary(row):\n",
        "    if row[\"neutral_flag\"] == 1: return 1  # neutral\n",
        "    return 2 if row[\"polarity_binary\"]==1 else 0  # 2=pos, 0=neg\n",
        "\n",
        "df[\"polarity_3cls\"] = df.apply(to_ternary, axis=1)\n",
        "df[[\"clean_text\",\"p_pos\",\"p_neg\",\"polarity_binary\",\"polarity_3cls\"]].head(10)"
      ],
      "metadata": {
        "id": "kyraKs3CfC3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. 타임스탬프별 감성분석**"
      ],
      "metadata": {
        "id": "5ICeUVmYfE_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "if df[\"ts\"].notna().any():\n",
        "    # 30초 bin (원하면 10/60초 등으로 바꿔도 됨)\n",
        "    ts_df = df.dropna(subset=[\"ts\"]).copy()\n",
        "    ts_df[\"bin\"] = (ts_df[\"ts\"].astype(\"int64\") // 10**9) // 30\n",
        "\n",
        "    agg = ts_df.groupby(\"bin\").agg(\n",
        "        n=(\"clean_text\",\"count\"),\n",
        "        mean_pos=(\"p_pos\",\"mean\"),\n",
        "        std_pos=(\"p_pos\",\"std\")\n",
        "    ).reset_index()\n",
        "    agg[\"synchrony_idx\"] = 1 - agg[\"std_pos\"].fillna(0)\n",
        "\n",
        "    display(agg.head())\n",
        "\n",
        "    plt.figure(figsize=(10,4)); plt.plot(agg[\"bin\"], agg[\"mean_pos\"], label=\"Mean P(pos)\")\n",
        "    plt.ylabel(\"Mean P(pos)\"); plt.xlabel(\"Time bin (30s)\"); plt.title(\"Sentiment over Time\"); plt.legend(); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10,4)); plt.plot(agg[\"bin\"], agg[\"synchrony_idx\"], label=\"Synchrony (1 - std)\")\n",
        "    plt.ylabel(\"Synchrony Index\"); plt.xlabel(\"Time bin (30s)\"); plt.title(\"Emotional Synchrony over Time\"); plt.legend(); plt.show()\n",
        "\n",
        "    agg.to_csv(\"/content/timebins_sentiment_synchrony.csv\", index=False)\n",
        "else:\n",
        "    print(\"타임스탬프가 없어서 시계열/동조도를 건너뜁니다.\")"
      ],
      "metadata": {
        "id": "fR7T-_tufIYd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}